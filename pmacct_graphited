#!/usr/bin/python
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Bernd Zeimetz <bernd@bzed.de>
Copyright (C) 2014 conova communications GmbH

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

from setproctitle import setproctitle
from application import log
from application.process import process, ProcessError

from watchdog.observers import Observer
from watchdog.events import RegexMatchingEventHandler, FileSystemEvent
from setproctitle import setproctitle

import time
import os
import re
import sys
import signal
import json

import graphitesend

class PmacctDirectoryHandlerException(Exception):
    pass

class PmacctDirectoryHandler(RegexMatchingEventHandler):

    def __init__(self,
            graphite_prefix,
            name,
            local_as,
            default_as,
            renormalization_factor=1,
            graphite_server='localhost',
            graphite_port=2003,
            debug=False):
        self.local_as = local_as
        self.default_as = default_as
        self.renormalization_factor = renormalization_factor
        self.graphite_server = graphite_server
        self.graphite_port = graphite_port
        self.graphitesender = None
        self.debug = debug
        self.error_count = 0
        self._file_start_match_re = re.compile(r'^--START \(([0-9]+)\+([0-9]+)\)--$')
        RegexMatchingEventHandler.__init__( self,
                                            regexes=[r'^pmacct_[0-9]+\.json$'],
                                            ignore_directories=True,
                                            case_sensitive=True
                                            )

    def _graphite_connect(self):
        self.graphitesender = graphitesend.init(
                prefix=graphite_prefix,
                system_name=name,
                graphite_server=self.graphite_server,
                graphite_port=self.graphite_port,
                debug=self.debug
        )


    def _renormalize(self, flow_bytes, flow_packets, renormalization_factor=self.renormalization_factor):
        if renormalization_factor==1:
            return (flow_bytes, flow_packets)
# usrf from pmacct:
#bpratio = queue[x]->bytes_counter/queue[x]->packet_counter;
#queue[x]->bytes_counter = queue[x]->bytes_counter*r;
#queue[x]->packet_counter = queue[x]->bytes_counter/bpratio; /* hmmm */
        bpratio = float(flow_bytes) / float(flow_packets)
        flow_bytes = flow_bytes * renormalization_factor
        flow_packets = flow_bytes / bpratio
        return (flow_bytes, flow_packets)


    def normalize_and_send_metric_list(self, metric_list, timestamp, interval):
        result_list = []
        for metric, flow_bytes, flow_packets in metric_list:
            # renormalize to fix sampling
            flow_bytes, flow_packets = self._renormalize(flow_bytes, flow_packets)
            # re-use renormalize function to calculate byte/packets per second
            flow_bytes, flow_packets = self._renormalize(flow_bytes, flow_packets, (1/float(interval)))
            result_list.append(('%s.bytes'   %(metric,), flow_bytes))
            result_list.append(('%s.packets' %(metric,), flow_packetc))
        if not self.graphitesender:
            self._graphite_connect()
        try:
            self.graphitesender.send_list(result_list, timestamp=(timestamp+interval/2))
        except Exception, e:
            raise PmacctDirectoryHandlerException('Graphite transport failed: \n%s' %(str(e)))


    def parse_pmacct_file(self, filename):
        try:
            with open(filename) as f:
                content = f.readlines()
        except Exception, e:
            raise PmacctDirectoryHandlerException('Failed to read file %s: %s' %(filename, str(e)))

        pmacct_data=[ json.loads(x) for x in content[1:-1] ]
        if content[-1] != '--END--':
            raise PmacctDirectoryHandlerException('--END-- tag missing in %s' %(filename,))
        try:
            timestamp, interval = self._file_start_match_re.match(content[0]).groups()
        except Exception, e:
            raise PmacctDirectoryHandlerException('--START... -- tag missing or not parsable in %s' %(filename,))

        # replace AS 0 by our default AS
        if self.default_as and self.default_as > 0:
            for entry in pmacct_data:
                for entry_key in ["as_dst", "as_src", "peer_dst", "peer_src"]:
                    if entry.has_key(entry_key) and entry[entry_key]==0:
                        entry[entry_key]=self.default_as

        return (pmacct_data, timestamp, interval)


    def on_created(self, event):
        super(PmacctDirectoryHandler, self).on_created(event)
        if event.is_directory:
            return
        self.handle_pmacct_file(event.src_path)


    def handle_pmacct_file(self, filename):
        try:
            pmacct_data, timestamp, interval = self.parse_pmacct_file(filename)
            pmacct_metrics = self.parse_pmacct_data(pmacct_data, timestamp, interval)
            self._graphite_connect()
            normalize_and_send_metric_list(pmacct_metrics, timestamp, interval)
        except PmacctDirectoryHandlerException, e:
            self.error_count = self.error_count + 1
            if self.error_count >= 5:
                raise
        else:
            self.error_count = 0
            os.remove(filename)


    def parse_pmacct_data(pmacct_data, timestamp, interval):
        """ parse pmacct_data into a list of metrics we can send.
            Needs to be overridden!"""
        pass


class PmacctASDirectoryHandler(PmacctDirectoryHandler):

    def parse_pmacct_data(self, pmacct_data, timestamp, interval):
        return self._parse_pmacct_data(pmacct_data, timestamp, interval, "as_dst", "as_src")

    def _parse_pmacct_data(self, pmacct_data, timestamp, interval, as_dst="as_dst", as_src="as_src"):
        metric_list = []
        for entry in pmacct_data:
            if entry[as_dst] in self.local_as or entry[as_dst] == self.default_as:
                metric_name = "%s.%s.in" %(str(entry[as_dst]), str(entry[as_src]))
            elif entry[as_src] in self.local_as or entry[as_src] == self.default_as:
                 metric_name = "%s.%s.out" %(str(entry[as_dst]), str(entry[as_src]))
            else:
                log.fatal("Neither %s nor %s known as local AS, can't handle %s!" %(str(entry[as_dst]),
                                                                                    str(entry[as_src]),
                                                                                    str(entry)))
                continue
            metric_list.append((metric_name, entry["bytes"], entry["packets"]))
        return metric_list
        
        
    
class PmacctPeerDirectoryHandler(PmacctASDirectoryHandler):

    def parse_pmacct_data(self, pmacct_data, timestamp, interval):
        return self._parse_pmacct_data(pmacct_data, timestamp, interval, "peer_dst", "peer_src")



class PmacctGraphiteD(object):


    def __init__(self,
                 local_as,
                 default_as,
                 graphite_prefix,
                 pmacct_aggregations,
                 renormalization_factor,
                 graphite_server,
                 graphite_port,
                 debug):
        self.stop_now = False
        self.observer = Observer()
        self.local_as = local_as
        self.default_as = default_as
        self.graphite_prefix = graphite_prefix
        self.pmacct_aggregations = pmacct_aggregations
        self.renormalization_factor = renormalization_factor
        self.graphite_server = graphite_server
        self.graphite_port = graphite_port
        self.debug = debug

        self.eventhandler_types = {
            'as'    : PmacctASDirectoryHandler,
            'peer'  : PmacctPeerDirectoryHandler
        }


    def run(self):
#        def __init__(self,
#                graphite_prefix,
#                name,
#                local_as,
#                default_as,
#                renormalization_factor=1,
#                graphite_server='localhost',
#                graphite_port=2003,
#                debug=False):


        for name, data in self.pmacct_aggregations.iteritems():
            handler = self.eventhandler_types[data['type']](
                    self.graphite_prefix,
                    name,
                    self.local_as,
                    self.default_as,
                    self.renormalization_factor,
                    self.graphite_server,
                    self.graphite_port,
                    self.debug)
            observer.schedule(handler, data['spool_dirctory'], recursive=False)


        self.observer.start()
        while not self.stop_now:
            time.sleep(1)
        self.observer.stop()
        self.observer.join()

    def stop(self):
        self.stop_now = True

if __name__ == "__main__":
    from argparse import ArgumentParser
    from os.path import basename

    name = os.path.basename(sys.argv[0])

    epilog = '%s - delivering your pmacct statistics to graphite since 2014' %(name,)

    parser = ArgumentParser(epilog=epilog)
    parser.add_argument('-N', '--nodaemon',
                        action='store_true',
                        dest='nodaemon',
                        default=False,
                        help='do not run as daemon and log to stdout/stderr')
    parser.add_argument('-d', '--debug',
                        action='store_true',
                        dest='debug',
                        default=False,
                        help='enable debugging')
    parser.add_argument('-l', '--local-as',
                        action='append',
                        dest='local_as',
                        help='mark given AS number as local; can be specified as often as necessary',
                        type=int,
                        required=True)
    parser.add_argument('-a', '--default-as',
                        action='store',
                        dest='default_as',
                        help='default AS number, AS "0" will be replaced by this number in graphite',
                        default=None,
                        type=int)
    parser.add_argument('-g', '--graphite-prefix',
                        action='store',
                        dest='graphite_prefix',
                        help='prefix for generated graphite metric names',
                        default='network.pmacct',
                        type=str)
    parser.add_argument('-p', '--pmacct-aggregations',
                        action='append',
                        dest='pmacct_aggregations_args',
                        help='''pmacct aggregation name and directory we want to track;
                        Format: graphite_name:type:spool_directory;
                        Valid types: peer,as;
                        can be specified as often as necessary''',
                        required=True,
                        type=str)
    parser.add_argument('-r', '--renormalization-factor',
                        action='store',
                        dest='renormalization_factor',
                        help='''Applies the renormalization factor to counters,
                                suitable for use in conjunction with uniform sampling methods.''',
                        default=1,
                        type=int)
    parser.add_argument('-s', '--graphite-server',
                        action='store',
                        dest='graphite_server',
                        help='graphite server and port:  server:2013, default: localhost:2003',
                        default='localhost:2003',
                        type=str)
    options = parser.parse_args()

    setproctitle('%s' %(name,) )

    if options.debug:
        DEBUG=True

    log.msg("Starting %s." % name)
    if not options.nodaemon:
        pidfile = process.runtime_file('%s.pid' % name)
        try:
            process.daemonize(pidfile)
        except ProcessError, e:
            log.fatal(str(e))
            sys.exit(1)
        else:
            log.start_syslog(name)
    log.msg("%s started" % name)


    # parse pmacct_aggregations into a dict
    pmacct_aggregations = {}
    for pmacct_aggregation in options.pmacct_aggregations_args:
        try:
            graphite_name, agg_type, spool_dirctory = pmacct_aggregation.split(':')
            if not graphite_name:
                raise Exception('graphite_name must not be empty!')
            graphite_name = graphite_name.strip('.')
            if not agg_type in ['as', 'peer']:
                raise Exception('unknown aggregation type "%s", please specify as or peer!' %(agg_type, ))
            if not os.path.isdir(spool_dirctory):
                raise Exception('directory "%s" does not exist' %(spool_dirctory))
            if pmacct_aggregations.has_key(graphite_name):
                raise Exception('please specify "%s" as aggregation name once only' %(graphite_name,))

        except Exception, e:
            log.fatal("Failed to parse option '-p %s': '%s'" %(pmacct_aggregation, str(e)))
            sys.exit(2)
        else:
            pmacct_aggregations[graphite_name] = {}
            pmacct_aggregations[graphite_name]['type'] = agg_type
            pmacct_aggregations[graphite_name]['spool_dirctory'] = spool_dirctory

    pgd = PmacctGraphiteD(options.local_as,
                          options.default_as,
                          options.graphite_prefix.strip('.'),
                          pmacct_aggregations,
                          options.renormalization_factor)

    try:
        pgd.run()
    except KeyboardInterrupt, SystemExit:
        pgd.stop()

